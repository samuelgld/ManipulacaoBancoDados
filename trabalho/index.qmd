---
title: "Importa√ß√£o de dados em Julia"
format: revealjs
editor: visual
---

## Importa√ß√£o de JSON em Julia

###### Gabriel Braga, Samuel Dias, Raul Rocha

Arquivos JSON s√£o excelentes para flexibilidade e estruturas hier√°rquicas, mas s√£o notoriamente mais lentos e pesados para processar do que formatos bin√°rios ou CSV. O ecossistema Julia aborda isso priorizando **tipagem est√°tica** e **aloca√ß√£o zero** onde poss√≠vel.

## Ferramenta Principal: `JSON3.jl`

Embora exista o pacote antigo `JSON.jl`, o padr√£o moderno para alta performance √© o **`JSON3.jl`**.

-   **Por que ele √© r√°pido?** O `JSON3` tenta evitar ao m√°ximo alocar mem√≥ria nova. Ele cria "views" (visualiza√ß√µes) sobre o texto original em vez de copiar strings para novos objetos.

-   **Integra√ß√£o com Structs:** Ele brilha quando voc√™ diz exatamente qual o formato dos dados (usando Structs), permitindo que o compilador do Julia gere c√≥digo de m√°quina otimizado para aquele layout espec√≠fico.

    ```{julia}
    #| eval: false

    # Lendo uma string ou arquivo

    # json_string = """{"nome": "Julia", "velocidade": "alta"}"""
    # = JSON3.read(json_string)

    # Acesso direto (como se fosse um objeto/dicion√°rio)
    #println(dados.nome)
    ```

Se voc√™ receber um arquivo de 5GB que √© um √∫nico objeto JSON (come√ßa com `{` e termina com `}`), o streaming √© muito dif√≠cil. O `JSON3` utiliza `Mmap` (Memory Mapping) para lidar com isso. Ele mapeia o arquivo do disco para a mem√≥ria virtual, permitindo que voc√™ navegue pelo JSON gigante sem carregar tudo na RAM f√≠sica de uma vez.

### Exemplo: Um √önico Objeto JSON Gigante:

```{julia}
#using JSON3, Mmap

# Mapeia o arquivo sem ler tudo imediatamente

#dados = open("arquivo_unico_gigante.json") do io
#    JSON3.read(Mmap.mmap(io))
#end
```

## Introdu√ß√£o do dataset

Este conjunto de dados √© um subconjunto das informa√ß√µes de neg√≥cios, avalia√ß√µes e usu√°rios do Yelp. Ele foi originalmente criado para o **Yelp Dataset Challenge**, que √© uma oportunidade para estudantes realizarem pesquisas ou an√°lises com os dados do Yelp e compartilharem suas descobertas.

No conjunto de dados mais recente, voc√™ encontrar√° informa√ß√µes sobre empresas em **8 √°reas metropolitanas** nos Estados Unidos e no Canad√°. \## O dataset est√° dispon√≠vel em <https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset>

O dataset cont√©m 5 arquivos JSON, para a apresenta√ß√£o de importa√ß√£o de dados volumosos, escolhemos um de aproximadamente 110mb pois o c√≥digo n√£o conseguiu rodar nada acima de 1gb para arquivos JSON.

Segue o c√≥digo.

## Leitura em Julia (JSON3)

```{r}
library(JuliaCall)
julia_setup(install = FALSE)
```

```{julia}
Pkg.add("JSON3")
```

## 

```{julia}
#| label: load-data-json
#| echo: true

# ==============================================================================
# LEITURA DE DADOS: DATA.JSON
# ==============================================================================

using JSON
using Printf # Para formatar o tempo de execu√ß√£o

# 1. Defini√ß√£o do Arquivo
# O arquivo agora se chama "data.json" e est√° no diret√≥rio local
arquivo = "data.json"

# Inicializamos um vetor vazio para armazenar os registros
dados = []

# 2. Leitura com Cron√¥metro
if isfile(arquivo)
    println("üîÑ Lendo arquivo '$arquivo'...")

    # @elapsed mede o tempo de execu√ß√£o do bloco em segundos
    tempo_gasto = @elapsed begin
        
        # Abre o arquivo em modo leitura ("r")
        open(arquivo, "r") do f
            # Itera sobre cada linha do arquivo individualmente
            for linha in eachline(f)
                if !isempty(strip(linha))
                    # Converte a linha de texto em um objeto Julia (Dict)
                    registro = JSON.parse(linha)
                    push!(dados, registro)
                end
            end
        end
        
    end
  open("tempo_julia.txt", "w") do io
    write(io, string(tempo_gasto))
  end
    # 3. Exibi√ß√£o dos Resultados
    println("‚úÖ Leitura conclu√≠da!")
    
    # Formata o tempo com 6 casas decimais
    @printf("‚è±Ô∏è Tempo total: %.6f segundos\n", tempo_gasto)
    
    println("üìä Registros processados: ", length(dados))

else
    println("‚ùå Erro: O arquivo '$arquivo' n√£o foi encontrado no diret√≥rio.")
    println("Diret√≥rio atual: ", pwd())
ends
```

## Leitura em Python (Pandas)

```{python}
#| label: benchmark-pandas-fix
#| echo: true

import pandas as pd
import time
import sys
import io

# ==============================================================================
# 1. CONFIGURA√á√ÉO DE SEGURAN√áA DO CONSOLE (BLINDAGEM)
# ==============================================================================
# Isso impede que o erro 'surrogates not allowed' trave o script ao imprimir mensagens.
try:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
except Exception:
    pass

# ==============================================================================
# 2. LEITURA COM PANDAS
# ==============================================================================
arquivo = "data.json"

print(f"üêº [Pandas] Iniciando leitura segura: {arquivo}")

inicio = time.time()
total_registros = 0
sucesso = False

try:
    # chunksize: L√™ em blocos para n√£o estourar a RAM
    # lines=True: Assume que √© um JSON por linha (formato padr√£o de big data)
    reader = pd.read_json(
        arquivo, 
        lines=True, 
        chunksize=100000, 
        encoding="utf-8",
        encoding_errors="replace" # Ignora bytes corrompidos no arquivo
    )

    for i, chunk in enumerate(reader):
        qtd_chunk = len(chunk)
        total_registros += qtd_chunk
        
        # Feedback a cada bloco processado
        print(f"Processando bloco {i}... ({qtd_chunk} linhas)")

    # Se chegou aqui, o loop terminou sem erros
    sucesso = True

except ValueError as e:
    # repr(e) √© o segredo: ele imprime a representa√ß√£o t√©cnica do erro
    # escapando caracteres estranhos, evitando o UnicodeEncodeError no print.
    print(f"\n‚ùå ERRO DE VALOR (Prov√°vel formato incorreto):")
    print(f"Detalhe t√©cnico: {repr(e)}") 

except Exception as e:
    print(f"\n‚ùå ERRO GERAL:")
    print(f"Detalhe t√©cnico: {repr(e)}")

# ==============================================================================
# 3. RESULTADOS
# ==============================================================================
fim = time.time()
tempo_total = fim - inicio
with open("tempo_python.txt", "w") as f:
    f.write(str(tempo_total))
if sucesso:
    print("-" * 30)
    print(f"‚úÖ SUCESSO COMPLETO.")
    print(f"‚è±Ô∏è Tempo: {tempo_total:.4f} s")
    print(f"üìä Registros: {total_registros}")
else:
    print("-" * 30)
    print(f"‚ö†Ô∏è A leitura parou no meio devido ao erro acima.")
    print(f"‚è±Ô∏è Tempo at√© a falha: {tempo_total:.4f} s")
```

## Leitura em R (Arrow e jsonlite)

```{r}
#| label: benchmark-r-comparison
#| echo: true

# ==============================================================================
# COMPARATIVO R: jsonlite vs arrow
# ==============================================================================

# Instala√ß√£o (se necess√°rio)
# install.packages(c("jsonlite", "arrow"))

library(jsonlite)
library(arrow)

arquivo <- "data.json"

# Vari√°veis para armazenar os tempos
tempo_jsonlite <- NA
tempo_arrow <- NA

cat(paste("üìÇ Arquivo alvo:", arquivo, "\n\n"))

# ------------------------------------------------------------------------------
# 1. Leitura com JSONLITE (Tradicional)
# ------------------------------------------------------------------------------
cat("üêå [jsonlite] Iniciando leitura (isso pode demorar)...\n")
start_j <- Sys.time()

tryCatch({
  # Usamos stream_in pois fromJSON costuma estourar a RAM com arquivos grandes
  con <- file(arquivo, open = "r", encoding = "UTF-8")
  df_jsonlite <- stream_in(con, verbose = FALSE, pagesize = 10000)
  close(con)
  
  end_j <- Sys.time()
  tempo_jsonlite <- as.numeric(difftime(end_j, start_j, units = "secs"))
  
  cat(sprintf("‚úÖ jsonlite concluiu em: %.4f segundos\n", tempo_jsonlite))
  cat(sprintf("üìä Linhas lidas: %d\n", nrow(df_jsonlite)))
  
  # --- LIMPEZA DE MEM√ìRIA CR√çTICA ---
  # Como o arquivo tem 5GB, n√£o podemos manter dois dataframes na mem√≥ria.
  # Removemos o primeiro antes de tentar o segundo.
  rm(df_jsonlite)
  gc() # For√ßa o Garbage Collector do R a liberar a RAM
  cat("üßπ Mem√≥ria limpa para o pr√≥ximo teste.\n\n")

}, error = function(e) {
  cat("‚ùå jsonlite falhou (possivelmente falta de mem√≥ria ou encoding).\n")
  print(e)
  if(exists("con") && isOpen(con)) close(con)
})

# ------------------------------------------------------------------------------
# 2. Leitura com ARROW (Alta Performance)
# ------------------------------------------------------------------------------
cat("üöÄ [arrow] Iniciando leitura...\n")
start_a <- Sys.time()

tryCatch({
  # O arrow usa C++ e multithreading
  df_arrow <- read_json_arrow(arquivo)
  
  end_a <- Sys.time()
  tempo_arrow <- as.numeric(difftime(end_a, start_a, units = "secs"))
  
  cat(sprintf("‚úÖ arrow concluiu em: %.4f segundos\n", tempo_arrow))
  cat(sprintf("üìä Linhas lidas: %d\n", nrow(df_arrow)))

}, error = function(e) {
  cat("‚ùå arrow falhou.\n")
  print(e)
})

# ------------------------------------------------------------------------------
# 3. RESULTADO FINAL DO DUELO
# ------------------------------------------------------------------------------
cat("\n=========================================\n")
cat("üèÜ RESULTADO DO BENCHMARK (R)\n")
cat("=========================================\n")

if (!is.na(tempo_jsonlite) && !is.na(tempo_arrow)) {
  cat(sprintf("üê¢ jsonlite: %.4f s\n", tempo_jsonlite))
  cat(sprintf("üêá arrow:    %.4f s\n", tempo_arrow))
  
  diferenca <- tempo_jsonlite / tempo_arrow
  cat(sprintf("\n‚ö° O Arrow foi %.1fx mais r√°pido que o jsonlite.\n", diferenca))
} else {
  cat("‚ö†Ô∏è N√£o foi poss√≠vel comparar (um dos m√©todos falhou).\n")
}
```

## Compara√ß√£o dos resultados

```{r}
#| label: benchmark-final-r-ascii
#| echo: true

# ==============================================================================
# üìù INPUT: INSIRA SEUS TEMPOS AQUI
# ==============================================================================
# Crie um Data Frame com os resultados.
# Substitua os valores num√©ricos pelos que voc√™ anotou.

ler_tempo <- function(arquivo) {
  if (file.exists(arquivo)) {
    val <- as.numeric(readLines(arquivo, warn = FALSE))
    return(val)
  } else {
    return(NA) # Retorna NA se o arquivo n√£o existir (c√©lula n√£o rodou)
  }
}

tempo_python <- ler_tempo("tempo_python.txt")
tempo_julia <- ler_tempo("tempo_julia.txt")

dados <- data.frame(
  Metodo = c("Julia (JSON3 + Mmap)", "R (Arrow)", "Python (Pandas)", "R (jsonlite)"),
  Tempo = c(tempo_julia, tempo_arrow, tempo_python, tempo_jsonlite), # <--- SEUS VALORES AQUI
  stringsAsFactors = FALSE
)


# ==============================================================================
# GERADOR DE TABELA (R Base)
# ==============================================================================

# 1. Ordenar do mais r√°pido para o mais lento
dados <- dados[order(dados$Tempo), ]

melhor_tempo <- dados$Tempo[1]
pior_tempo <- tail(dados$Tempo, 1)
tamanho_grafico <- 30 # Largura m√°xima da barra

# Cabe√ßalho
cat("\n")
cat(paste(rep("=", 75), collapse = ""), "\n")
cat(" RESULTADO FINAL DO BENCHMARK (Menor tempo = Melhor)\n")
cat(paste(rep("=", 75), collapse = ""), "\n\n")

# Colunas
cat(sprintf("%-25s | %-10s | %-15s | %s\n", 
            "LINGUAGEM / METODO", "TEMPO (s)", "DIFERENCA", "GRAFICO"))
cat(paste(rep("-", 75), collapse = ""), "\n")

# Loop para imprimir linhas
for(i in 1:nrow(dados)) {
  nome <- dados$Metodo[i]
  tempo <- dados$Tempo[i]
  
  # C√°lculo do fator
  fator <- tempo / melhor_tempo
  
  # C√°lculo da barra
  # Evita divis√£o por zero
  if (pior_tempo > 0) {
    qtd_barras <- round((tempo / pior_tempo) * tamanho_grafico)
  } else {
    qtd_barras <- 0
  }
  
  # Garante pelo menos 1 caractere para visualiza√ß√£o e cria a string da barra
  qtd_barras <- max(1, qtd_barras)
  barra <- paste(rep("#", qtd_barras), collapse = "")
  
  # Texto do status
  if (fator == 1.0) {
    status <- "CAMPEAO"
  } else {
    status <- sprintf("%.1fx lento", fator)
  }
  
  # Impress√£o formatada
  cat(sprintf("%-25s | %10.4f | %-15s | %s\n", 
              nome, tempo, status, barra))
}

cat(paste(rep("-", 75), collapse = ""), "\n")
```

## Dataset - NYC TLC Trip Record Data

Usaremos um dos dataset p√∫blicos do "NYC TLC Trip Record Data" (encontrado em: <a>https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page</a>) no formato Parquet.

O site disponibiliza registros de viagens realizadas pelo servi√ßo de "NYC Taxi and Limousine Commission (TLC)". Usaremos o "High Volume For-Hire Vehicle Trip Records" (fhvhv_tripdata_2021-01.parquet) que cont√©m dados sobre: tempo de viagem, n√∫mero de passageiros, taxas da corrida, forma de pagamento, entre outros.

## O que √© Parquet?

Parquet √© um formato de armazenamento colunar, projetado para an√°lise de dados em larga escala. Ele organiza os dados por colunas, o que reduz tamanho, melhora compress√£o e acelera opera√ß√µes anal√≠ticas.

Facilidades

-   Alta compress√£o ‚Üí arquivos menores e mais r√°pidos de transferir.
-   Leitura seletiva de colunas ‚Üí reduz tempo e mem√≥ria.
-   Integra√ß√£o nativa com motores anal√≠ticos (Arrow, DuckDB, Spark, Polars).

Dificuldades

-   Leitura completa pode consumir muita mem√≥ria, devendo ser combinada com ferramentas como DuckDB/Arrow para evitar materializa√ß√£o total.
-   N√£o √© ideal para atualiza√ß√µes linha a linha (n√£o √© um formato para ‚Äúedi√ß√£o‚Äù).

```{r eval = FALSE}
if (!requireNamespace("arrow", quietly = TRUE)) install.packages("arrow")
if (!requireNamespace("duckdb", quietly = TRUE)) install.packages("duckdb")
if (!requireNamespace("DBI", quietly = TRUE)) install.packages("DBI")
library(arrow); library(duckdb); library(DBI)
```

```{r eval=FALSE}
library(arrow)
ds <- open_dataset("data/fhvhv_tripdata_2021-01.parquet", format = "parquet")
ds$schema
```

## Leitura direta - R

```{r eval=TRUE}
library(arrow)
sys = system.time({
df_r <- read_parquet('data/fhvhv_tripdata_2021-01.parquet')
})
print(sys)
print(dim(df_r))
head(df_r)
```

## Sele√ß√£o de colunas (carregamento parcial) - R

```{r eval=TRUE}
system.time({
df_r_sel <- read_parquet(
  "data/fhvhv_tripdata_2021-01.parquet",
  col_select = c(
    "pickup_datetime",
    "dropoff_datetime",
    "trip_miles",
    "trip_time",
    "tips"
  )                                 
)
head(df_r_sel)
})
print(dim(df_r_sel))
head(df_r_sel)
```

## Consultas usando DuckDB - R

```{r eval=TRUE}
system.time({
con <- DBI::dbConnect(duckdb::duckdb())
DBI::dbGetQuery(con, "
  SELECT COUNT(*) AS n
  FROM read_parquet('data/fhvhv_tripdata_2021-01.parquet')
")
DBI::dbGetQuery(con, "
  SELECT
    PULocationID,
    AVG(trip_miles) AS avg_miles,
    AVG(trip_time) AS avg_time
  FROM read_parquet('data/fhvhv_tripdata_2021-01.parquet')
  GROUP BY PULocationID
  ORDER BY PULocationID
  LIMIT 10
")
DBI::dbDisconnect(con, shutdown=TRUE)
})
```

## Boas pr√°ticas para grandes volumes

-   Use formatos colunares (Parquet, Arrow) e selecione apenas colunas necess√°rias.

-   Prefira uma camada de consulta (DuckDB) para an√°lises explorat√≥rias sem "materializar" tudo.

-   Considere partitioning e ler em blocos.

-   O fluxo ideal para grandes Parquet: DuckDB para explora√ß√£o + "materializar" apenas o que precisar.
